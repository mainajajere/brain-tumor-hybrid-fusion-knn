import os, nbformat as nbf

nb = nbf.v4.new_notebook()
cells = []

def md(x): return nbf.v4.new_markdown_cell(x)
def code(x): return nbf.v4.new_code_cell(x)

cells += [
md("# Brain Tumor MRI Classification: Independent Validation + Ablation + XAI\n"
"This notebook reproduces a lightweight, self-contained version of the dual-backbone late-fusion + KNN pipeline with:\n"
"- Independent validation (image-level, 64/16/20 stratified split)\n"
"- Ablations: backbones (MobileNetV2, EfficientNetV2B0, Fusion) and KNN hyperparameters\n"
"- Explainability: Grad-CAM and SHAP (aux softmax head for XAI only)\n"
"Place images under data/images/{glioma,meningioma,pituitary,notumor}.\n"),

code("# If running on Colab, set DO_INSTALL=True to install packages; in Codespaces you may keep False.\n"
"DO_INSTALL = False\n"
"if DO_INSTALL:\n"
"    import sys, subprocess\n"
"    pkgs = [\n"
"      'tensorflow==2.17.0','shap==0.46.0','numpy==1.26.4','pandas==2.1.4','scikit-learn==1.4.2',\n"
"      'matplotlib==3.8.4','opencv-python-headless==4.9.0.80','Pillow==10.3.0','pyyaml==6.0.1','seaborn==0.13.2','tqdm==4.66.4'\n"
"    ]\n"
"    subprocess.check_call([sys.executable,'-m','pip','install','-q',*pkgs])\n"
"import os, glob, json, random, yaml, cv2\n"
"import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n"
"from tqdm import tqdm\n"
"import tensorflow as tf\n"
"from tensorflow.keras import layers, models, optimizers, callbacks\n"
"from sklearn.model_selection import train_test_split\n"
"from sklearn.neighbors import KNeighborsClassifier\n"
"from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, f1_score, accuracy_score\n"
"from sklearn.preprocessing import label_binarize\n"
"print('TF:', tf.version)\n"),

code("# Reproducibility and config\n"
"SEED = 1337\n"
"random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n"
"CLASSES = ['glioma','meningioma','pituitary','notumor']\n"
"N_CLASSES = len(CLASSES)\n"
"IMAGE_SIZE = 224\n"
"DATA_ROOT = 'data/images'\n"
"OUT_DIR = 'outputs'; os.makedirs(OUT_DIR, exist_ok=True)\n"),

code("# Data check and split (64/16/20 stratified)\n"
"rows=[]\n"
"for i,c in enumerate(CLASSES):\n"
"    for ext in ('.png','.jpg','.jpeg'):\n"
"        rows += [{'path':p,'label':i,'class':c} for p in glob.glob(os.path.join(DATA_ROOT,c,f'*{ext}'))]\n"
"df = pd.DataFrame(rows)\n"
"assert len(df)>0, f'No images found under {DATA_ROOT}'\n"
"tr,val,te = 0.64,0.16,0.20\n"
"tv_df, test_df = train_test_split(df, test_size=te, stratify=df['label'], random_state=SEED)\n"
"val_rel = val/(tr+val)\n"
"train_df, val_df = train_test_split(tv_df, test_size=val_rel, stratify=tv_df['label'], random_state=SEED)\n"
"def counts(x):\n"
"    return x.groupby('class').size().reindex(CLASSES).fillna(0).astype(int)\n"
"display(pd.DataFrame({'train':counts(train_df),'val':counts(val_df),'test':counts(test_df)}))\n"),

code("# Backbones and preprocessing\n"
"def mobilenet_v2_backbone(image_size=224, freeze=True):\n"
"    base = tf.keras.applications.MobileNetV2(include_top=False, weights='imagenet', input_shape=(image_size,image_size,3))\n"
"    base.trainable = not freeze\n"
"    return base\n"
"def efficientnet_v2_b0_backbone(image_size=224, freeze=True):\n"
"    base = tf.keras.applications.EfficientNetV2B0(include_top=False, weights='imagenet', input_shape=(image_size,image_size,3))\n"
"    base.trainable = not freeze\n"
"    return base\n"
"def load_image(path, image_size):\n"
"    b = tf.io.read_file(path)\n"
"    img = tf.image.decode_image(b, channels=3, expand_animations=False)\n"
"    img = tf.image.resize(img, (image_size, image_size))\n"
"    img = tf.cast(img, tf.float32)\n"
"    return img\n"
"def extract_features(df, use_mb=True, use_ef=True, image_size=224):\n"
"    mb = mobilenet_v2_backbone(image_size, True) if use_mb else None\n"
"    ef = efficientnet_v2_b0_backbone(image_size, True) if use_ef else None\n"
"    feats, labels = [], []\n"
"    for _, r in tqdm(df.iterrows(), total=len(df)):\n"
"        img = load_image(r['path'], image_size)\n"
"        vecs=[]\n"
"        if mb is not None:\n"
"            x = tf.keras.applications.mobilenet_v2.preprocess_input(img)\n"
"            fm = mb(tf.expand_dims(x,0), training=False)\n"
"            vecs.append(tf.reduce_mean(fm, axis=[1,2]).numpy().squeeze())\n"
"        if ef is not None:\n"
"            x = tf.keras.applications.efficientnet_v2.preprocess_input(img)\n"
"            fm = ef(tf.expand_dims(x,0), training=False)\n"
"            vecs.append(tf.reduce_mean(fm, axis=[1,2]).numpy().squeeze())\n"
"        fused = np.concatenate(vecs, axis=-1) if len(vecs)>1 else vecs[0]\n"
"        feats.append(fused); labels.append(int(r['label']))\n"
"    X = np.stack(feats); y = np.array(labels)\n"
"    return X, y\n"),

code("# Ablations + KNN grid\n"
"def eval_knn(X_tr,y_tr,X_te,y_te,k=5,metric='euclidean',weights='distance'):\n"
"    clf = KNeighborsClassifier(n_neighbors=k, metric=metric, weights=weights)\n"
"    clf.fit(X_tr,y_tr)\n"
"    y_pred = clf.predict(X_te); y_prob = clf.predict_proba(X_te)\n"
"    acc = accuracy_score(y_te,y_pred); f1m = f1_score(y_te,y_pred,average='macro')\n"
"    return acc,f1m,clf,y_pred,y_prob\n"
"print('Extracting features: MBV2'); Xtr_mb,ytr_mb = extract_features(train_df,True,False,IMAGE_SIZE); Xva_mb,yva_mb = extract_features(val_df,True,False,IMAGE_SIZE); Xte_mb,yte_mb = extract_features(test_df,True,False,IMAGE_SIZE)\n"
"print('Extracting features: EFV2B0'); Xtr_ef,ytr_ef = extract_features(train_df,False,True,IMAGE_SIZE); Xva_ef,yva_ef = extract_features(val_df,False,True,IMAGE_SIZE); Xte_ef,yte_ef = extract_features(test_df,False,True,IMAGE_SIZE)\n"
"print('Extracting features: Fusion'); Xtr_fu,ytr_fu = extract_features(train_df,True,True,IMAGE_SIZE); Xva_fu,yva_fu = extract_features(val_df,True,True,IMAGE_SIZE); Xte_fu,yte_fu = extract_features(test_df,True,True,IMAGE_SIZE)\n"
"grid_k=[1,3,5,7,9]; grid_metric=['euclidean','manhattan']; grid_weights=['uniform','distance']\n"
"def grid_search(Xtr,ytr,Xva,yva):\n"
"    best=None; rows=[]\n"
"    for k in grid_k:\n"
"        for m in grid_metric:\n"
"            for w in grid_weights:\n"
"                acc,f1m,clf,,=eval_knn(Xtr,ytr,Xva,yva,k=k,metric=m,weights=w)\n"
"                rows.append({'k':k,'metric':m,'weights':w,'val_acc':acc,'val_f1m':f1m})\n"
"                if best is None or f1m>best['val_f1m']:\n"
"                    best={'k':k,'metric':m,'weights':w,'val_f1m':f1m}\n"
"    return pd.DataFrame(rows), best\n"
"df_mb,best_mb = grid_search(Xtr_mb,ytr_mb,Xva_mb,yva_mb)\n"
"df_ef,best_ef = grid_search(Xtr_ef,ytr_ef,Xva_ef,yva_ef)\n"
"df_fu,best_fu = grid_search(Xtr_fu,ytr_fu,Xva_fu,yva_fu)\n"
"display({'MBV2 grid':df_mb.head(10),'EFV2B0 grid':df_ef.head(10),'Fusion grid':df_fu.head(10)})\n"
"print('Best MBV2:',best_mb); print('Best EFV2B0:',best_ef); print('Best Fusion:',best_fu)\n"
"def final_eval(Xtr,ytr,Xte,yte,b):\n"
"    return eval_knn(np.vstack([Xtr]),np.hstack([ytr]),Xte,yte,k=b['k'],metric=b['metric'],weights=b['weights'])\n"
"res={}\n"
"res['MBV2']=final_eval(np.vstack([Xtr_mb,Xva_mb]),np.hstack([ytr_mb,yva_mb]),Xte_mb,yte_mb,best_mb)\n"
"res['EFV2B0']=final_eval(np.vstack([Xtr_ef,Xva_ef]),np.hstack([ytr_ef,yva_ef]),Xte_ef,yte_ef,best_ef)\n"
"res['Fusion']=final_eval(np.vstack([Xtr_fu,Xva_fu]),np.hstack([ytr_fu,yva_fu]),Xte_fu,yte_fu,best_fu)\n"
"for k,(acc,f1m,,,_) in res.items(): print(k,'test_acc=',acc,'test_f1m=',f1m)\n"),

code("# Plots for Fusion result\n"
"def plot_confusion(y_true,y_pred,class_names,out_path):\n"
"    cm = confusion_matrix(y_true,y_pred,labels=list(range(len(class_names))))\n"
"    plt.figure(figsize=(5,4))\n"
"    sns.heatmap(cm,annot=True,fmt='d',cmap='Blues',xticklabels=class_names,yticklabels=class_names)\n"
"    plt.xlabel('Predicted'); plt.ylabel('True'); plt.tight_layout(); plt.savefig(out_path,dpi=200); plt.close(); return cm\n"
"def plot_roc(y_true,y_prob,class_names,out_path):\n"
"    y_true_bin = label_binarize(y_true,classes=list(range(len(class_names))))\n"
"    plt.figure(figsize=(5,4))\n"
"    for i,c in enumerate(class_names):\n"
"        fpr,tpr,_ = roc_curve(y_true_bin[:,i], y_prob[:,i]); plt.plot(fpr,tpr,label=f'{c} (AUC={auc(fpr,tpr):.2f})')\n"
"    plt.plot([0,1],[0,1],'k--'); plt.xlabel('FPR'); plt.ylabel('TPR'); plt.legend(); plt.tight_layout(); plt.savefig(out_path,dpi=200); plt.close()\n"
"acc,f1m,clf,y_pred,y_prob = res['Fusion']\n"
"print('Fusion final test_acc=',acc,'test_f1m=',f1m)\n"
"os.makedirs(OUT_DIR,exist_ok=True)\n"
"cm = plot_confusion(yte_fu,y_pred,CLASSES,os.path.join(OUT_DIR,'confusion.png'))\n"
"plot_roc(yte_fu,y_prob,CLASSES,os.path.join(OUT_DIR,'roc_curves.png'))\n"
"pd.DataFrame(classification_report(yte_fu,y_pred,target_names=CLASSES,output_dict=True)).transpose().to_csv(os.path.join(OUT_DIR,'class_metrics.csv'))\n"),

code("# XAI: aux softmax head for Grad-CAM and SHAP\n"
"def build_aux_models(image_size=224, n_classes=4):\n"
"    inputs = layers.Input(shape=(image_size,image_size,3))\n"
"    mb_in = tf.keras.applications.mobilenet_v2.preprocess_input(inputs)\n"
"    ef_in = tf.keras.applications.efficientnet_v2.preprocess_input(inputs)\n"
"    mb = tf.keras.applications.MobileNetV2(include_top=False, weights='imagenet', input_shape=(image_size,image_size,3))\n"
"    ef = tf.keras.applications.EfficientNetV2B0(include_top=False, weights='imagenet', input_shape=(image_size,image_size,3))\n"
"    mb.trainable=False; ef.trainable=False\n"
"    mb_conv = mb(mb_in, training=False)\n"
"    ef_conv = ef(ef_in, training=False)\n"
"    gap_mb = layers.GlobalAveragePooling2D()(mb_conv)\n"
"    gap_ef = layers.GlobalAveragePooling2D()(ef_conv)\n"
"    fused = layers.Concatenate()([gap_mb,gap_ef])\n"
"    fused = layers.Dropout(0.5)(fused)\n"
"    logits = layers.Dense(n_classes, activation='softmax')(fused)\n"
"    logits_model = models.Model(inputs=inputs, outputs=logits, name='aux_logits')\n"
"    cam_model    = models.Model(inputs=inputs, outputs=[logits, mb_conv, ef_conv], name='aux_cam')\n"
"    return logits_model, cam_model\n"
"def df_to_ds(df,batch=16,shuffle=False):\n"
"    def _load(path,label):\n"
"        b=tf.io.read_file(path); img=tf.image.decode_image(b,3,expand_animations=False)\n"
"        img=tf.image.resize(img,(IMAGE_SIZE,IMAGE_SIZE)); img=tf.cast(img,tf.float32)\n"
"        return img, tf.cast(label, tf.int32)\n"
"    ds=tf.data.Dataset.from_tensor_slices((df['path'].values, df['label'].values)).map(_load, num_parallel_calls=tf.data.AUTOTUNE)\n"
"    if shuffle: ds=ds.shuffle(1024,reshuffle_each_iteration=True)\n"
"    return ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n"
"logits_model, cam_model = build_aux_models(IMAGE_SIZE, N_CLASSES)\n"
"opt = optimizers.Adam(1e-3); logits_model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
"es = callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n"
"ds_tr = df_to_ds(train_df,16,True); ds_va = df_to_ds(val_df,16,False)\n"
"logits_model.fit(ds_tr, validation_data=ds_va, epochs=30, callbacks=[es], verbose=1)\n"),

code("# Grad-CAM overlays\n"
"def gradcam_for_pred(img_tensor, class_idx):\n"
"    with tf.GradientTape() as tape:\n"
"        logits, conv_mb, conv_ef = cam_model(tf.expand_dims(img_tensor,0), training=False)\n"
"        score = logits[:, class_idx]\n"
"    grads_mb = tape.gradient(score, conv_mb); grads_ef = tape.gradient(score, conv_ef)\n"
"    w_mb = tf.reduce_mean(grads_mb, axis=(1,2)); w_ef = tf.reduce_mean(grads_ef, axis=(1,2))\n"
"    cam_mb = tf.reduce_sum(w_mb[:,None,None,:]conv_mb,axis=-1)[0].numpy(); cam_ef = tf.reduce_sum(w_ef[:,None,None,:]conv_ef,axis=-1)[0].numpy()\n"
"    cam_mb = np.maximum(cam_mb,0); cam_ef = np.maximum(cam_ef,0)\n"
"    cam_mb = (cam_mb-cam_mb.min())/(cam_mb.max()+1e-8); cam_ef = (cam_ef-cam_ef.min())/(cam_ef.max()+1e-8)\n"
"    cam = (cam_mb+cam_ef)/2.0; cam = cv2.resize(cam,(IMAGE_SIZE,IMAGE_SIZE)); return cam\n"
"def overlay_heatmap(raw_rgb, cam, alpha=0.35):\n"
"    heat = cv2.applyColorMap((cam255).astype(np.uint8), cv2.COLORMAP_JET); heat = cv2.cvtColor(heat, cv2.COLOR_BGR2RGB)\n"
"    return (heatalpha + raw_rgb*(1-alpha)).astype(np.uint8)\n"
"os.makedirs(os.path.join(OUT_DIR,'xai','gradcam'), exist_ok=True)\n"
"subset = test_df.groupby('class').head(3)\n"
"for _, r in subset.iterrows():\n"
"    b=tf.io.read_file(r['path']); img=tf.image.decode_image(b,3,expand_animations=False); img=tf.image.resize(img,(IMAGE_SIZE,IMAGE_SIZE))\n"
"    raw=tf.cast(tf.clip_by_value(img,0,255),tf.uint8).numpy(); img=tf.cast(img,tf.float32)\n"
"    pred=int(tf.argmax(logits_model(tf.expand_dims(img,0))[0]).numpy())\n"
"    cam=gradcam_for_pred(img,pred); over=overlay_heatmap(raw,cam,0.35)\n"
"    fn=f"{CLASSES[r['label']]}pred{CLASSES[pred]}{os.path.basename(r['path'])}.png"\n"
"    cv2.imwrite(os.path.join(OUT_DIR,'xai','gradcam',fn), cv2.cvtColor(over, cv2.COLOR_RGB2BGR))\n"
"print('Saved Grad-CAM to', os.path.join(OUT_DIR,'xai','gradcam'))\n"),

code("# SHAP explanations\n"
"import shap, matplotlib; matplotlib.use('Agg')\n"
"os.makedirs(os.path.join(OUT_DIR,'xai','shap'), exist_ok=True)\n"
"def load_img(path):\n"
"    b=tf.io.read_file(path); img=tf.image.decode_image(b,3,expand_animations=False); img=tf.image.resize(img,(IMAGE_SIZE,IMAGE_SIZE))\n"
"    return tf.cast(img,tf.float32)\n"
"bg=[]\n"
"for ci,c in enumerate(CLASSES):\n"
"    sample=train_df[train_df['label']==ci].head(5)\n"
"    for , rr in sample.iterrows(): bg.append(load_img(rr['path']))\n"
"if bg:\n"
"    bg = tf.stack(bg,0)\n"
"    explainer = shap.GradientExplainer(logits_model, bg)\n"
"    for ci,cname in enumerate(CLASSES):\n"
"        sample=test_df[test_df['label']==ci].head(2)\n"
"        if sample.empty: continue\n"
"        xs=tf.stack([load_img(p) for p in sample['path'].values],0)\n"
"        sv = explainer.shap_values(xs)\n"
"        preds = tf.argmax(logits_model(xs), axis=1).numpy()\n"
"        sv_list = [sv[p][i] for i,p in enumerate(preds)]\n"
"        shap.image_plot(sv_list, xs.numpy(), show=False)\n"
"        plt.savefig(os.path.join(OUT_DIR,'xai','shap',f'summary{cname}.png'), dpi=200, bbox_inches='tight'); plt.close()\n"
"    print('Saved SHAP images to', os.path.join(OUT_DIR,'xai','shap'))\n"
"else:\n"
"    print('No SHAP background images, skipping SHAP.')\n"),

code("# Save meta\n"
"meta={'seed':SEED,'image_size':IMAGE_SIZE,'classes':CLASSES,'tf_version':tf.version}\n"
"with open(os.path.join(OUT_DIR,'meta.json'),'w') as f: json.dump(meta,f,indent=2)\n"
"meta\n")
]

nb['cells'] = cells
os.makedirs('notebooks', exist_ok=True)
out_path = 'notebooks/BrainTumor_FusionKNN_Validation.ipynb'
with open(out_path, 'w', encoding='utf-8') as f:
nbf.write(nb, f)
print('Wrote', out_path)
