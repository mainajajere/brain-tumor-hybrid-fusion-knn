{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d52b470",
   "metadata": {},
   "source": [
    "# Brain Tumor MRI Classification: Validation + XAI (Notebook)\n",
    "\n",
    "This Colab runs the released pipeline end-to-end using the embedded demo dataset (10 images per class) stored in this repo under `data/images`.\n",
    "\n",
    "**Pipeline:**\n",
    "- Create stratified 64/16/20 splits\n",
    "- Extract features (MobileNetV2 + EfficientNetV2B0, GAP+concat)\n",
    "- Train KNN (k=5, Euclidean, distance weights)\n",
    "- Evaluate (confusion matrix, class metrics)\n",
    "- Display results\n",
    "\n",
    "**No Google Drive or Kaggle required by default.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8779c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi -L || true\n",
    "%cd /content\n",
    "!git clone -q https://github.com/mainajajere/brain-tumor-hybrid-fusion-knn.git\n",
    "%cd /content/brain-tumor-hybrid-fusion-knn\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "import os, sys, pathlib, yaml\n",
    "REPO = pathlib.Path('/content/brain-tumor-hybrid-fusion-knn')\n",
    "os.makedirs(REPO/'outputs', exist_ok=True)\n",
    "os.makedirs(REPO/'results', exist_ok=True)\n",
    "sys.path.append(str(REPO))\n",
    "print('‚úÖ Repo ready at', REPO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cdff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the embedded demo dataset under data/images (lowercase class names)\n",
    "DATA_ROOT = '/content/brain-tumor-hybrid-fusion-knn/data/images'\n",
    "CLASSES   = ['glioma','meningioma','pituitary','notumor']\n",
    "\n",
    "import os\n",
    "def have_dataset(root, classes):\n",
    "    return all(os.path.isdir(os.path.join(root,c)) and len(os.listdir(os.path.join(root,c)))>0 for c in classes)\n",
    "\n",
    "print('Dataset root:', DATA_ROOT)\n",
    "for c in CLASSES:\n",
    "    p = os.path.join(DATA_ROOT, c)\n",
    "    n = len(os.listdir(p)) if os.path.isdir(p) else 0\n",
    "    print(f'‚úÖ {c}: {n} images' if n > 0 else f'‚ùå {c}: MISSING')\n",
    "\n",
    "if not have_dataset(DATA_ROOT, CLASSES):\n",
    "    raise SystemExit('‚ùå Embedded demo dataset not found. Expected data/images/<class> folders.')\n",
    "else:\n",
    "    print('‚úÖ Dataset verified successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f636207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write config (64/16/20 split; KNN k=5 Euclidean distance weighting)\n",
    "cfg = {\n",
    "  'data': {\n",
    "    'root_dir': DATA_ROOT,\n",
    "    'classes': CLASSES,\n",
    "    'image_size': [224, 224],\n",
    "    'seed': 42,\n",
    "    'split': {'test': 0.20, 'val_from_train': 0.20}\n",
    "  },\n",
    "  'augment': {'rotation': 0.055, 'zoom': 0.10, 'translate': 0.10, 'hflip': True, 'contrast': 0.15},\n",
    "  'train': {'batch_size': 32, 'epochs': 50, 'optimizer': 'adam', 'lr': 0.001, 'dropout': 0.5},\n",
    "  'fusion': {'type': 'late', 'pooling': 'gap', 'concat': True},\n",
    "  'knn': {'n_neighbors': 5, 'metric': 'euclidean', 'weights': 'distance'},\n",
    "  'cv': {'n_folds': 5, 'stratify': True},\n",
    "  'xai': {'shap_background_per_class': 25}\n",
    "}\n",
    "os.makedirs('configs', exist_ok=True)\n",
    "with open('configs/config.yaml','w') as f:\n",
    "    yaml.safe_dump(cfg, f, sort_keys=False)\n",
    "print('‚úÖ Config written: configs/config.yaml')\n",
    "!head -20 configs/config.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c219e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, check the data splits\n",
    "print(\"=== Checking data splits ===\")\n",
    "!python scripts/check_split_counts.py --config configs/config.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9b1751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the complete pipeline\n",
    "print(\"=== Running full pipeline ===\")\n",
    "!python scripts/run_full_pipeline.py --config configs/config.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c3d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show key outputs\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "print(\"=== Pipeline Outputs ===\")\n",
    "outputs_to_check = [\n",
    "    'outputs/figures/confusion_matrix.png',\n",
    "    'outputs/figures/class_metrics.png',\n",
    "    'outputs/results/summary.txt'\n",
    "]\n",
    "\n",
    "for p in outputs_to_check:\n",
    "    print(f'\\nüìÅ {p}')\n",
    "    if p.endswith('.png') and os.path.exists(p):\n",
    "        display(Image(filename=p))\n",
    "        print('‚úÖ Displayed')\n",
    "    elif os.path.exists(p):\n",
    "        print('üìä Content:')\n",
    "        print(open(p).read())\n",
    "    else:\n",
    "        print('‚ùå MISSING - Pipeline may have failed')\n",
    "\n",
    "# Check if outputs directory was created\n",
    "if os.path.exists('outputs'):\n",
    "    print(f'\\n‚úÖ Outputs directory created with:')\n",
    "    !find outputs -type f | head -10\n",
    "else:\n",
    "    print('‚ùå No outputs directory created')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
